{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RkVLW3KXPYY8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/all_data.csv\")"
      ],
      "metadata": {
        "id": "s4oCkM3lPofM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9MRYbxQujKr",
        "outputId": "9f0a0aff-3844-4979-b76b-1b74e1f5cea1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tN3nX-GGRkTz",
        "outputId": "a963b350-4d30-4188-b008-fdfe6ff04cfc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              id                                       comment_text  split  \\\n",
              "0        1083994  He got his money... now he lies in wait till a...  train   \n",
              "1         650904  Mad dog will surely put the liberals in mental...  train   \n",
              "2        5902188  And Trump continues his lifelong cowardice by ...  train   \n",
              "3        7084460  \"while arresting a man for resisting arrest\".\\...   test   \n",
              "4        5410943     Tucker and Paul are both total bad ass mofo's.  train   \n",
              "...          ...                                                ...    ...   \n",
              "1999511  1018736  Another man shamming article. If white men did...  train   \n",
              "1999512   340016  \"no matter what is put in front of you regardi...  train   \n",
              "1999513   919629  The Democrat party aided and abetted by it's M...  train   \n",
              "1999514  5165492  I just don't find her a very good representati...  train   \n",
              "1999515  4984105  You know the Trump fanatics are trolling the G...  train   \n",
              "\n",
              "                          created_date  publication_id  parent_id  article_id  \\\n",
              "0        2017-03-06 15:21:53.675241+00              21        NaN      317120   \n",
              "1        2016-12-02 16:44:21.329535+00              21        NaN      154086   \n",
              "2        2017-09-05 19:05:32.341360+00              55        NaN      374342   \n",
              "3        2016-11-01 16:53:33.561631+00              13        NaN      149218   \n",
              "4        2017-06-14 05:08:21.997315+00              21        NaN      344096   \n",
              "...                                ...             ...        ...         ...   \n",
              "1999511  2017-02-20 07:20:49.964620+00              54        NaN      169202   \n",
              "1999512  2016-06-06 06:43:04.780968+00              21   339965.0      137961   \n",
              "1999513  2017-01-30 02:44:29.168863+00              54        NaN      164845   \n",
              "1999514  2017-04-22 18:42:02.442987+00              54        NaN      328877   \n",
              "1999515  2017-03-10 00:55:35.369198+00              54   807615.0      156960   \n",
              "\n",
              "           rating  funny  wow  ...  white  asian  latino  \\\n",
              "0        approved      0    0  ...    NaN    NaN     NaN   \n",
              "1        approved      0    0  ...    NaN    NaN     NaN   \n",
              "2        approved      1    0  ...    NaN    NaN     NaN   \n",
              "3        approved      0    0  ...    NaN    NaN     NaN   \n",
              "4        approved      0    0  ...    NaN    NaN     NaN   \n",
              "...           ...    ...  ...  ...    ...    ...     ...   \n",
              "1999511  approved      0    0  ...    0.8    0.0     0.0   \n",
              "1999512  approved      0    0  ...    0.0    0.0     0.0   \n",
              "1999513  rejected      0    1  ...    0.0    0.0     0.0   \n",
              "1999514  approved      1    0  ...    0.0    0.0     0.0   \n",
              "1999515  approved      1    0  ...    0.0    0.0     0.0   \n",
              "\n",
              "         other_race_or_ethnicity  physical_disability  \\\n",
              "0                            NaN                  NaN   \n",
              "1                            NaN                  NaN   \n",
              "2                            NaN                  NaN   \n",
              "3                            NaN                  NaN   \n",
              "4                            NaN                  NaN   \n",
              "...                          ...                  ...   \n",
              "1999511                      0.0             0.000000   \n",
              "1999512                      0.0             0.000000   \n",
              "1999513                      0.0             0.000000   \n",
              "1999514                      0.0             0.003717   \n",
              "1999515                      0.0             0.000000   \n",
              "\n",
              "         intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
              "0                                        NaN                            NaN   \n",
              "1                                        NaN                            NaN   \n",
              "2                                        NaN                            NaN   \n",
              "3                                        NaN                            NaN   \n",
              "4                                        NaN                            NaN   \n",
              "...                                      ...                            ...   \n",
              "1999511                                  0.0                            0.0   \n",
              "1999512                                  0.0                            0.0   \n",
              "1999513                                  0.0                            0.0   \n",
              "1999514                                  0.0                            0.0   \n",
              "1999515                                  0.0                            0.0   \n",
              "\n",
              "         other_disability  identity_annotator_count  toxicity_annotator_count  \n",
              "0                     NaN                         0                        67  \n",
              "1                     NaN                         0                        76  \n",
              "2                     NaN                         0                        63  \n",
              "3                     NaN                         0                        76  \n",
              "4                     NaN                         0                        80  \n",
              "...                   ...                       ...                       ...  \n",
              "1999511           0.00000                        10                        10  \n",
              "1999512           0.00000                        10                        10  \n",
              "1999513           0.00000                        11                        10  \n",
              "1999514           0.00000                       269                        10  \n",
              "1999515           0.00064                      1562                        10  \n",
              "\n",
              "[1999516 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18d4f1cf-5399-4db2-9b48-bf5d05d0bf4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>split</th>\n",
              "      <th>created_date</th>\n",
              "      <th>publication_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>funny</th>\n",
              "      <th>wow</th>\n",
              "      <th>...</th>\n",
              "      <th>white</th>\n",
              "      <th>asian</th>\n",
              "      <th>latino</th>\n",
              "      <th>other_race_or_ethnicity</th>\n",
              "      <th>physical_disability</th>\n",
              "      <th>intellectual_or_learning_disability</th>\n",
              "      <th>psychiatric_or_mental_illness</th>\n",
              "      <th>other_disability</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1083994</td>\n",
              "      <td>He got his money... now he lies in wait till a...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-03-06 15:21:53.675241+00</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>317120</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>650904</td>\n",
              "      <td>Mad dog will surely put the liberals in mental...</td>\n",
              "      <td>train</td>\n",
              "      <td>2016-12-02 16:44:21.329535+00</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>154086</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5902188</td>\n",
              "      <td>And Trump continues his lifelong cowardice by ...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-09-05 19:05:32.341360+00</td>\n",
              "      <td>55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>374342</td>\n",
              "      <td>approved</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7084460</td>\n",
              "      <td>\"while arresting a man for resisting arrest\".\\...</td>\n",
              "      <td>test</td>\n",
              "      <td>2016-11-01 16:53:33.561631+00</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>149218</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5410943</td>\n",
              "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-06-14 05:08:21.997315+00</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>344096</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999511</th>\n",
              "      <td>1018736</td>\n",
              "      <td>Another man shamming article. If white men did...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-02-20 07:20:49.964620+00</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>169202</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999512</th>\n",
              "      <td>340016</td>\n",
              "      <td>\"no matter what is put in front of you regardi...</td>\n",
              "      <td>train</td>\n",
              "      <td>2016-06-06 06:43:04.780968+00</td>\n",
              "      <td>21</td>\n",
              "      <td>339965.0</td>\n",
              "      <td>137961</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999513</th>\n",
              "      <td>919629</td>\n",
              "      <td>The Democrat party aided and abetted by it's M...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-01-30 02:44:29.168863+00</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>164845</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999514</th>\n",
              "      <td>5165492</td>\n",
              "      <td>I just don't find her a very good representati...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-04-22 18:42:02.442987+00</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>328877</td>\n",
              "      <td>approved</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003717</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>269</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999515</th>\n",
              "      <td>4984105</td>\n",
              "      <td>You know the Trump fanatics are trolling the G...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-03-10 00:55:35.369198+00</td>\n",
              "      <td>54</td>\n",
              "      <td>807615.0</td>\n",
              "      <td>156960</td>\n",
              "      <td>approved</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00064</td>\n",
              "      <td>1562</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1999516 rows × 46 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18d4f1cf-5399-4db2-9b48-bf5d05d0bf4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18d4f1cf-5399-4db2-9b48-bf5d05d0bf4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18d4f1cf-5399-4db2-9b48-bf5d05d0bf4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzaGp_3oRrJd",
        "outputId": "c2f1916f-678f-4b1f-be8f-a1c498097a44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1999516"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "6GeOzqxiS8ji",
        "outputId": "98dd95a5-8035-4fff-d71a-077e7538e151"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id  publication_id     parent_id    article_id         funny  \\\n",
              "count  1.999516e+06    1.999516e+06  1.134709e+06  1.999516e+06  1.999516e+06   \n",
              "mean   4.065400e+06    4.988997e+01  3.715138e+06  2.810257e+05  2.776687e-01   \n",
              "std    2.527563e+06    2.771895e+01  2.451507e+06  1.040778e+05  1.054819e+00   \n",
              "min    5.984800e+04    2.000000e+00  6.100600e+04  2.006000e+03  0.000000e+00   \n",
              "25%    8.565798e+05    2.100000e+01  7.930110e+05  1.600038e+05  0.000000e+00   \n",
              "50%    5.340220e+06    5.400000e+01  5.217531e+06  3.319250e+05  0.000000e+00   \n",
              "75%    5.955782e+06    5.400000e+01  5.774684e+06  3.662270e+05  0.000000e+00   \n",
              "max    7.194640e+06    1.150000e+02  6.333965e+06  3.995440e+05  1.020000e+02   \n",
              "\n",
              "                wow           sad         likes      disagree      toxicity  \\\n",
              "count  1.999516e+06  1.999516e+06  1.999516e+06  1.999516e+06  1.999516e+06   \n",
              "mean   4.437174e-02  1.089289e-01  2.441188e+00  5.808151e-01  1.029241e-01   \n",
              "std    2.458644e-01  4.555570e-01  4.712994e+00  1.854332e+00  1.970386e-01   \n",
              "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "50%    0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
              "75%    0.000000e+00  0.000000e+00  3.000000e+00  0.000000e+00  1.666667e-01   \n",
              "max    2.100000e+01  3.100000e+01  3.000000e+02  1.870000e+02  1.000000e+00   \n",
              "\n",
              "       ...          white          asian         latino  \\\n",
              "count  ...  448000.000000  448000.000000  448000.000000   \n",
              "mean   ...       0.056534       0.011886       0.006151   \n",
              "std    ...       0.215175       0.086906       0.058828   \n",
              "min    ...       0.000000       0.000000       0.000000   \n",
              "25%    ...       0.000000       0.000000       0.000000   \n",
              "50%    ...       0.000000       0.000000       0.000000   \n",
              "75%    ...       0.000000       0.000000       0.000000   \n",
              "max    ...       1.000000       1.000000       1.000000   \n",
              "\n",
              "       other_race_or_ethnicity  physical_disability  \\\n",
              "count            448000.000000        448000.000000   \n",
              "mean                  0.008158             0.001351   \n",
              "std                   0.042429             0.017461   \n",
              "min                   0.000000             0.000000   \n",
              "25%                   0.000000             0.000000   \n",
              "50%                   0.000000             0.000000   \n",
              "75%                   0.000000             0.000000   \n",
              "max                   1.000000             1.000000   \n",
              "\n",
              "       intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
              "count                        448000.000000                  448000.000000   \n",
              "mean                              0.001117                       0.012068   \n",
              "std                               0.016391                       0.089072   \n",
              "min                               0.000000                       0.000000   \n",
              "25%                               0.000000                       0.000000   \n",
              "50%                               0.000000                       0.000000   \n",
              "75%                               0.000000                       0.000000   \n",
              "max                               1.000000                       1.000000   \n",
              "\n",
              "       other_disability  identity_annotator_count  toxicity_annotator_count  \n",
              "count     448000.000000              1.999516e+06              1.999516e+06  \n",
              "mean           0.001219              1.431667e+00              8.775720e+00  \n",
              "std            0.014114              1.763593e+01              4.331605e+01  \n",
              "min            0.000000              0.000000e+00              3.000000e+00  \n",
              "25%            0.000000              0.000000e+00              4.000000e+00  \n",
              "50%            0.000000              0.000000e+00              4.000000e+00  \n",
              "75%            0.000000              0.000000e+00              6.000000e+00  \n",
              "max            0.600000              1.866000e+03              4.936000e+03  \n",
              "\n",
              "[8 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-024ccdc6-069a-4370-b28c-922ae5274881\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>publication_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>funny</th>\n",
              "      <th>wow</th>\n",
              "      <th>sad</th>\n",
              "      <th>likes</th>\n",
              "      <th>disagree</th>\n",
              "      <th>toxicity</th>\n",
              "      <th>...</th>\n",
              "      <th>white</th>\n",
              "      <th>asian</th>\n",
              "      <th>latino</th>\n",
              "      <th>other_race_or_ethnicity</th>\n",
              "      <th>physical_disability</th>\n",
              "      <th>intellectual_or_learning_disability</th>\n",
              "      <th>psychiatric_or_mental_illness</th>\n",
              "      <th>other_disability</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.134709e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.065400e+06</td>\n",
              "      <td>4.988997e+01</td>\n",
              "      <td>3.715138e+06</td>\n",
              "      <td>2.810257e+05</td>\n",
              "      <td>2.776687e-01</td>\n",
              "      <td>4.437174e-02</td>\n",
              "      <td>1.089289e-01</td>\n",
              "      <td>2.441188e+00</td>\n",
              "      <td>5.808151e-01</td>\n",
              "      <td>1.029241e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056534</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>0.006151</td>\n",
              "      <td>0.008158</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>0.001117</td>\n",
              "      <td>0.012068</td>\n",
              "      <td>0.001219</td>\n",
              "      <td>1.431667e+00</td>\n",
              "      <td>8.775720e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.527563e+06</td>\n",
              "      <td>2.771895e+01</td>\n",
              "      <td>2.451507e+06</td>\n",
              "      <td>1.040778e+05</td>\n",
              "      <td>1.054819e+00</td>\n",
              "      <td>2.458644e-01</td>\n",
              "      <td>4.555570e-01</td>\n",
              "      <td>4.712994e+00</td>\n",
              "      <td>1.854332e+00</td>\n",
              "      <td>1.970386e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.215175</td>\n",
              "      <td>0.086906</td>\n",
              "      <td>0.058828</td>\n",
              "      <td>0.042429</td>\n",
              "      <td>0.017461</td>\n",
              "      <td>0.016391</td>\n",
              "      <td>0.089072</td>\n",
              "      <td>0.014114</td>\n",
              "      <td>1.763593e+01</td>\n",
              "      <td>4.331605e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.984800e+04</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>6.100600e+04</td>\n",
              "      <td>2.006000e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.565798e+05</td>\n",
              "      <td>2.100000e+01</td>\n",
              "      <td>7.930110e+05</td>\n",
              "      <td>1.600038e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.340220e+06</td>\n",
              "      <td>5.400000e+01</td>\n",
              "      <td>5.217531e+06</td>\n",
              "      <td>3.319250e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.955782e+06</td>\n",
              "      <td>5.400000e+01</td>\n",
              "      <td>5.774684e+06</td>\n",
              "      <td>3.662270e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.666667e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.194640e+06</td>\n",
              "      <td>1.150000e+02</td>\n",
              "      <td>6.333965e+06</td>\n",
              "      <td>3.995440e+05</td>\n",
              "      <td>1.020000e+02</td>\n",
              "      <td>2.100000e+01</td>\n",
              "      <td>3.100000e+01</td>\n",
              "      <td>3.000000e+02</td>\n",
              "      <td>1.870000e+02</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.866000e+03</td>\n",
              "      <td>4.936000e+03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-024ccdc6-069a-4370-b28c-922ae5274881')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-024ccdc6-069a-4370-b28c-922ae5274881 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-024ccdc6-069a-4370-b28c-922ae5274881');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UsCt18uTiEa",
        "outputId": "6b9b4ad1-1961-41bd-edb0-5435473840ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'comment_text', 'split', 'created_date', 'publication_id',\n",
              "       'parent_id', 'article_id', 'rating', 'funny', 'wow', 'sad', 'likes',\n",
              "       'disagree', 'toxicity', 'severe_toxicity', 'obscene', 'sexual_explicit',\n",
              "       'identity_attack', 'insult', 'threat', 'male', 'female', 'transgender',\n",
              "       'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual',\n",
              "       'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu',\n",
              "       'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian',\n",
              "       'latino', 'other_race_or_ethnicity', 'physical_disability',\n",
              "       'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
              "       'other_disability', 'identity_annotator_count',\n",
              "       'toxicity_annotator_count'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data[\"toxicity\"].to_numpy().tolist()"
      ],
      "metadata": {
        "id": "U3XkOZqhUZvv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[\"comment_text\"].to_numpy().tolist()"
      ],
      "metadata": {
        "id": "4g1WlJPaUeNa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X) , type(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uymq9bw9UkaF",
        "outputId": "ab79d7a8-d5ee-4b95-a36e-d1636af538a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del data[\"parent_id\"]\n",
        "del data[\"id\"]\n",
        "del data[\"split\"]\n",
        "del data[\"created_date\"]\n",
        "del data[\"publication_id\"]\n",
        "del data[\"article_id\"]\n",
        "del data[\"rating\"]"
      ],
      "metadata": {
        "id": "6ORzYApeTrDw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing data\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdvbFtSrSrzM",
        "outputId": "41864c21-2cd4-4673-998b-f52bd5e14713"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pre_process_data(main , flag = False):\n",
        "\n",
        "    if (flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            Original Data\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" , main[0])\n",
        "        print(\"2 :\" ,main[1])\n",
        "        print(\"3 :\" ,main[2])\n",
        "        print(\"4 :\" ,main[3])\n",
        "        print(\"5 :\" ,main[4])\n",
        "\n",
        "\n",
        "    # Step 1 - lowercasing\n",
        "\n",
        "    lower_cased_data = []\n",
        "    for sent in main:\n",
        "        # if(type(sent) == float):\n",
        "        #     print(sent)\n",
        "        #     break\n",
        "        lower_cased_data.append(sent.lower())\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After Lower Casing\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,lower_cased_data[0])\n",
        "        print(\"2 :\" ,lower_cased_data[1])\n",
        "        print(\"3 :\" ,lower_cased_data[2])\n",
        "        print(\"4 :\" ,lower_cased_data[3])\n",
        "        print(\"5 :\" ,lower_cased_data[4])\n",
        "\n",
        "    # Step 2 - Tokenization\n",
        "\n",
        "    token = WhitespaceTokenizer()\n",
        "\n",
        "    tokenized_data = []\n",
        "    for sent in lower_cased_data:\n",
        "        tokenized_data.append(token.tokenize(sent))\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After Toeknization\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,tokenized_data[0])\n",
        "        print(\"2 :\" ,tokenized_data[1])\n",
        "        print(\"3 :\" ,tokenized_data[2])\n",
        "        print(\"4 :\" ,tokenized_data[3])\n",
        "        print(\"5 :\" ,tokenized_data[4])\n",
        "\n",
        "    \n",
        "    # Step 3 - removing stop words\n",
        "\n",
        "    stopWords = set(stopwords.words('english'))\n",
        "    no_stop_data = []\n",
        "\n",
        "    for li in tokenized_data:\n",
        "        temp = []\n",
        "        for word in li:\n",
        "            if (word not in stopWords):\n",
        "                temp.append(word)\n",
        "        no_stop_data.append(temp)\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After Stop Words removal\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,no_stop_data[0])\n",
        "        print(\"2 :\" ,no_stop_data[1])\n",
        "        print(\"3 :\" ,no_stop_data[2])\n",
        "        print(\"4 :\" ,no_stop_data[3])\n",
        "        print(\"5 :\" ,no_stop_data[4])\n",
        "\n",
        "    # Step 4 - removing punctuations\n",
        "\n",
        "    puncts = string.punctuation\n",
        "    no_punc_data = []\n",
        "\n",
        "    for li in no_stop_data:\n",
        "        temp = []\n",
        "        for word in li:\n",
        "            temp_word = \"\"\n",
        "            for alp in word:\n",
        "                if (alp not in puncts):\n",
        "                    temp_word += alp\n",
        "            temp.append(temp_word)\n",
        "        no_punc_data.append(temp)\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After Punctuations removal\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,no_punc_data[0])\n",
        "        print(\"2 :\" ,no_punc_data[1])\n",
        "        print(\"3 :\" ,no_punc_data[2])\n",
        "        print(\"4 :\" ,no_punc_data[3])\n",
        "        print(\"5 :\" ,no_punc_data[4])\n",
        "\n",
        "    # Step 5 - Removing white spaces\n",
        "\n",
        "    final_data = []\n",
        "\n",
        "    for li in no_punc_data:\n",
        "        temp = []\n",
        "        for word in li:\n",
        "            if (word != ''):\n",
        "                temp.append(word)\n",
        "        final_data.append(temp)\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After White Space removal\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,final_data[0])\n",
        "        print(\"2 :\" ,final_data[1])\n",
        "        print(\"3 :\" ,final_data[2])\n",
        "        print(\"4 :\" ,final_data[3])\n",
        "        print(\"5 :\" ,final_data[4])\n",
        "\n",
        "    return final_data"
      ],
      "metadata": {
        "id": "CfWEnpQiRty8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(axis = 0 , inplace = True)"
      ],
      "metadata": {
        "id": "EWOufDJcWxvM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JraRw_lAW39x",
        "outputId": "8b63dd32-8227-44d9-ba80-a3ef585b4734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "448000"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CaQ0UvIXGmg",
        "outputId": "7feed656-82dd-407c-8ba8-3466116fad4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pre_processed = pre_process_data(X)"
      ],
      "metadata": {
        "id": "AChJEqk2VCGz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_pre_processed"
      ],
      "metadata": {
        "id": "5vwn3t-qVhiR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will need to join the tokenized inputs first\n",
        "X_final = []\n",
        "for i in range(len(X)):\n",
        "    inp = X[i]\n",
        "    X_final.append(' '.join(inp))"
      ],
      "metadata": {
        "id": "hzkz9AGLcWVJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_final"
      ],
      "metadata": {
        "id": "z7nLnxdTcr7G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "bkBdOhbkXmZg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train , Y_test = train_test_split(X,Y)"
      ],
      "metadata": {
        "id": "owuWUEUEYHfr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train)\n",
        "X_train = vectorizer.transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "fKC2Ve8vYOv8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cniov2Nub_W5",
        "outputId": "9ae82aaf-158b-4822-bd9a-5620b4ba6b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "# Convert your textual data to a list of lists of words\n",
        "text_data = [sentence.split() for sentence in X]\n",
        "\n",
        "# Train a Word2Vec model on your text data\n",
        "model = Word2Vec(sentences=text_data, size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Convert your text data into vectors using the Word2Vec model\n",
        "vectors = []\n",
        "for sentence in text_data:\n",
        "    sentence_vector = np.zeros(100)\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            word_vector = model.wv[word]\n",
        "            sentence_vector += word_vector\n",
        "        except KeyError:\n",
        "            pass\n",
        "    vectors.append(sentence_vector)\n"
      ],
      "metadata": {
        "id": "wINjCMnVhHdq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Ylw42shLgK",
        "outputId": "47647d42-0c3f-4e4e-c2a0-60941151eb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "448000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoLXTnePjz3y",
        "outputId": "2e6bedd1-faee-489e-ff18-2d24a50ac775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = pd.DataFrame(vectors)\n",
        "encodings.to_csv(\"encoding.csv\")"
      ],
      "metadata": {
        "id": "7cG6uRky4Vs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"encoding.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1KIpefPK4euR",
        "outputId": "87f7a292-21b2-4b34-c95c-182ab54bc8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4035332f-3554-4a0f-a94b-f69a6ec50ce9\", \"encoding.csv\", 852346738)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"encoding.csv\")"
      ],
      "metadata": {
        "id": "evLiSAtR6roS",
        "outputId": "750345f7-fdaa-482c-d21c-ad44632eb80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_281f17c4-96a0-4426-82ed-dafe325637cb\", \"encoding.csv\", 852346738)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train , Y_test = train_test_split(vectors,Y)"
      ],
      "metadata": {
        "id": "O_enI8BTkw6h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train an SVM model on the training data\n",
        "clf = SVC(kernel='linear', C=1, random_state=42)\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the SVM model\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "YB6naFvjlh_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "ucz46fpX433q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "# Predict the labels for the test data\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the SVM model\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mQrpkb75FR_",
        "outputId": "53ccb97f-31d5-4deb-884a-02c58a91b462"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9183214285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "zObpDZHa33_0",
        "outputId": "641b892c-4992-42ec-d319-4fbe41f12912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-931765772341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_temp = []\n",
        "for val in Y_train:\n",
        "    if val>0.5:\n",
        "        Y_train_temp.append(1)\n",
        "    else:\n",
        "        Y_train_temp.append(0)\n",
        "Y_train = Y_train_temp"
      ],
      "metadata": {
        "id": "9kAZZ8smmkNr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test_temp = []\n",
        "for val in Y_test:\n",
        "    if val>0.5:\n",
        "        Y_test_temp.append(1)\n",
        "    else:\n",
        "        Y_test_temp.append(0)\n",
        "Y_test = Y_test_temp"
      ],
      "metadata": {
        "id": "11ZbJtBwmpxV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "0NKdItq9FJMN",
        "outputId": "eeb2aa22-7cb6-46b8-b3b2-fafc760a7cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-01edcedc-383a-4d32-baa8-4dc952594592\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-01edcedc-383a-4d32-baa8-4dc952594592\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bad-words.csv to bad-words (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starring out toxic words"
      ],
      "metadata": {
        "id": "5ZKp2twD1fzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_words = pd.read_csv(\"bad-words (3).csv\").to_numpy().tolist()"
      ],
      "metadata": {
        "id": "YnfkaDvb1jCU"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detoxify(sent):\n",
        "\n",
        "    # First we will check whether the sent is toxic or not using our SVM model\n",
        "\n",
        "    # if the sent is not toxic then just return the original sentence\n",
        "\n",
        "    # else\n",
        "\n",
        "    detoxified_sentence = \"\"\n",
        "    for word in sent.split(' '):\n",
        "        if([word] in toxic_words):\n",
        "            # We found a toxic word\n",
        "            detoxified_sentence += '*'*len(word)\n",
        "        else:\n",
        "            detoxified_sentence += word\n",
        "        detoxified_sentence += \" \"\n",
        "    return detoxified_sentence"
      ],
      "metadata": {
        "id": "bxK4-nZ11lSK"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying on a particular input"
      ],
      "metadata": {
        "id": "hh5P-jHg8abW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "id": "oCMQgDnlCyuC",
        "outputId": "eeb970e4-f0f6-4230-e9b6-3ae56c50ceab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'oh yes evil christian missionaries many slaughtered indians lost lives due disease starvation etc lumped genocidists mention yes make word make stories'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_1 = X[0]\n",
        "input_2 = X[1]"
      ],
      "metadata": {
        "id": "fKMZog4Z8d1g"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = [input_1,input_2]"
      ],
      "metadata": {
        "id": "MYHxa0oXDNxU"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = pre_process_data(X_final)"
      ],
      "metadata": {
        "id": "q6UaLoA59CIg"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_final[1]"
      ],
      "metadata": {
        "id": "S2DpyVLU-WRX",
        "outputId": "b41b6b9d-7677-46d8-d49f-3ab7f3a62740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['black',\n",
              " 'racist',\n",
              " 'crap',\n",
              " 'still',\n",
              " 'gm',\n",
              " 'website',\n",
              " 'stopped',\n",
              " 'talking',\n",
              " 'black',\n",
              " 'people',\n",
              " 'long',\n",
              " 'ago',\n",
              " 'afraid',\n",
              " 'life',\n",
              " 'since',\n",
              " '8090',\n",
              " 'crime',\n",
              " 'black',\n",
              " 'people',\n",
              " 'kinda',\n",
              " 'makes',\n",
              " 'sense',\n",
              " 'oh',\n",
              " 'wait',\n",
              " 'thats',\n",
              " 'profiling',\n",
              " 'driving',\n",
              " 'black',\n",
              " 'know',\n",
              " 'leftist',\n",
              " 'marxists',\n",
              " 'blm',\n",
              " 'nutjobs',\n",
              " 'change',\n",
              " 'names',\n",
              " 'fast',\n",
              " 'one',\n",
              " 'keep',\n",
              " 'facts',\n",
              " 'speak',\n",
              " 'like',\n",
              " 'wash',\n",
              " 'away',\n",
              " 'letting',\n",
              " 'identity',\n",
              " 'marxists',\n",
              " 'spew',\n",
              " 'racist',\n",
              " 'hatred',\n",
              " 'white',\n",
              " 'people',\n",
              " 'think',\n",
              " 'commit',\n",
              " 'crimes',\n",
              " 'world',\n",
              " 'f',\n",
              " 'would',\n",
              " 'give',\n",
              " 'time',\n",
              " 'day',\n",
              " 'clean',\n",
              " 'sht',\n",
              " 'first',\n",
              " 'people',\n",
              " 'problem']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_fin = []\n",
        "for i in range(len(X_final)):\n",
        "    inp = X_final[i]\n",
        "    X_fin.append(' '.join(inp))"
      ],
      "metadata": {
        "id": "eDJt5BDf-dcZ"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = [sentence.split() for sentence in X_fin]\n",
        "embed = []\n",
        "\n",
        "for sentence in text_data:\n",
        "    sentence_vector = np.zeros(100)\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            word_vector = model.wv[word]\n",
        "            sentence_vector += word_vector\n",
        "        except KeyError:\n",
        "            pass\n",
        "    embed.append(sentence_vector)"
      ],
      "metadata": {
        "id": "bQXXe-Vi9anJ"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_fin = logreg.predict(embed)"
      ],
      "metadata": {
        "id": "5kIzOIKq-0K0"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_fin"
      ],
      "metadata": {
        "id": "hYn7wwZS_B5M",
        "outputId": "aa3b8125-ba21-4960-cf24-78dad1616f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test[11]"
      ],
      "metadata": {
        "id": "cIs6s49w_KKS",
        "outputId": "fef36989-c25c-4de9-f918-81b07d9c39bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "li = [X_test[155]]\n",
        "y_predd = logreg.predict(li)\n",
        "y_predd"
      ],
      "metadata": {
        "id": "MOhzoA8D_tyg",
        "outputId": "51de59f5-43e0-4fad-9f5d-cf6660f14e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1]"
      ],
      "metadata": {
        "id": "fGMSPz0UAsk8",
        "outputId": "855683f5-bd5e-4b80-eb1f-0bbf75a1ec7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'black racist crap still gm website stopped talking black people long ago afraid life since 8090 crime black people kinda makes sense it oh wait thats profiling driving black know leftist marxists blm nutjobs change names fast one keep up facts speak like this wash away letting identity marxists spew racist hatred white people think not commit crimes world f would give time day clean sht first people problem'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detoxify(X[1])"
      ],
      "metadata": {
        "id": "yMrbq3GODmzw",
        "outputId": "4b97a0f9-ee9a-4baa-f014-f07ef24471d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'***** ****** **** still gm website stopped talking ***** people long ago afraid life since 8090 ***** ***** people kinda makes sense it oh wait thats profiling driving ***** know ******* marxists blm ******* change names fast one keep up facts speak like this wash away letting identity marxists spew ****** hatred white people think not commit ****** world f would give time day clean sht first people problem '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8f1USU9FmuJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}