{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RkVLW3KXPYY8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/all_data.csv\")"
      ],
      "metadata": {
        "id": "s4oCkM3lPofM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tN3nX-GGRkTz",
        "outputId": "a425b45a-2cc2-4b2a-8685-4a2869bdcf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              id                                       comment_text  split  \\\n",
              "0        1083994  He got his money... now he lies in wait till a...  train   \n",
              "1         650904  Mad dog will surely put the liberals in mental...  train   \n",
              "2        5902188  And Trump continues his lifelong cowardice by ...  train   \n",
              "3        7084460  \"while arresting a man for resisting arrest\".\\...   test   \n",
              "4        5410943     Tucker and Paul are both total bad ass mofo's.  train   \n",
              "...          ...                                                ...    ...   \n",
              "1999511  1018736  Another man shamming article. If white men did...  train   \n",
              "1999512   340016  \"no matter what is put in front of you regardi...  train   \n",
              "1999513   919629  The Democrat party aided and abetted by it's M...  train   \n",
              "1999514  5165492  I just don't find her a very good representati...  train   \n",
              "1999515  4984105  You know the Trump fanatics are trolling the G...  train   \n",
              "\n",
              "                          created_date  publication_id  parent_id  article_id  \\\n",
              "0        2017-03-06 15:21:53.675241+00              21        NaN      317120   \n",
              "1        2016-12-02 16:44:21.329535+00              21        NaN      154086   \n",
              "2        2017-09-05 19:05:32.341360+00              55        NaN      374342   \n",
              "3        2016-11-01 16:53:33.561631+00              13        NaN      149218   \n",
              "4        2017-06-14 05:08:21.997315+00              21        NaN      344096   \n",
              "...                                ...             ...        ...         ...   \n",
              "1999511  2017-02-20 07:20:49.964620+00              54        NaN      169202   \n",
              "1999512  2016-06-06 06:43:04.780968+00              21   339965.0      137961   \n",
              "1999513  2017-01-30 02:44:29.168863+00              54        NaN      164845   \n",
              "1999514  2017-04-22 18:42:02.442987+00              54        NaN      328877   \n",
              "1999515  2017-03-10 00:55:35.369198+00              54   807615.0      156960   \n",
              "\n",
              "           rating  funny  wow  ...  white  asian  latino  \\\n",
              "0        approved      0    0  ...    NaN    NaN     NaN   \n",
              "1        approved      0    0  ...    NaN    NaN     NaN   \n",
              "2        approved      1    0  ...    NaN    NaN     NaN   \n",
              "3        approved      0    0  ...    NaN    NaN     NaN   \n",
              "4        approved      0    0  ...    NaN    NaN     NaN   \n",
              "...           ...    ...  ...  ...    ...    ...     ...   \n",
              "1999511  approved      0    0  ...    0.8    0.0     0.0   \n",
              "1999512  approved      0    0  ...    0.0    0.0     0.0   \n",
              "1999513  rejected      0    1  ...    0.0    0.0     0.0   \n",
              "1999514  approved      1    0  ...    0.0    0.0     0.0   \n",
              "1999515  approved      1    0  ...    0.0    0.0     0.0   \n",
              "\n",
              "         other_race_or_ethnicity  physical_disability  \\\n",
              "0                            NaN                  NaN   \n",
              "1                            NaN                  NaN   \n",
              "2                            NaN                  NaN   \n",
              "3                            NaN                  NaN   \n",
              "4                            NaN                  NaN   \n",
              "...                          ...                  ...   \n",
              "1999511                      0.0             0.000000   \n",
              "1999512                      0.0             0.000000   \n",
              "1999513                      0.0             0.000000   \n",
              "1999514                      0.0             0.003717   \n",
              "1999515                      0.0             0.000000   \n",
              "\n",
              "         intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
              "0                                        NaN                            NaN   \n",
              "1                                        NaN                            NaN   \n",
              "2                                        NaN                            NaN   \n",
              "3                                        NaN                            NaN   \n",
              "4                                        NaN                            NaN   \n",
              "...                                      ...                            ...   \n",
              "1999511                                  0.0                            0.0   \n",
              "1999512                                  0.0                            0.0   \n",
              "1999513                                  0.0                            0.0   \n",
              "1999514                                  0.0                            0.0   \n",
              "1999515                                  0.0                            0.0   \n",
              "\n",
              "         other_disability  identity_annotator_count  toxicity_annotator_count  \n",
              "0                     NaN                         0                        67  \n",
              "1                     NaN                         0                        76  \n",
              "2                     NaN                         0                        63  \n",
              "3                     NaN                         0                        76  \n",
              "4                     NaN                         0                        80  \n",
              "...                   ...                       ...                       ...  \n",
              "1999511           0.00000                        10                        10  \n",
              "1999512           0.00000                        10                        10  \n",
              "1999513           0.00000                        11                        10  \n",
              "1999514           0.00000                       269                        10  \n",
              "1999515           0.00064                      1562                        10  \n",
              "\n",
              "[1999516 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d60f635-8f58-4ce4-9720-f7c1c09e1374\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>split</th>\n",
              "      <th>created_date</th>\n",
              "      <th>publication_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>funny</th>\n",
              "      <th>wow</th>\n",
              "      <th>...</th>\n",
              "      <th>white</th>\n",
              "      <th>asian</th>\n",
              "      <th>latino</th>\n",
              "      <th>other_race_or_ethnicity</th>\n",
              "      <th>physical_disability</th>\n",
              "      <th>intellectual_or_learning_disability</th>\n",
              "      <th>psychiatric_or_mental_illness</th>\n",
              "      <th>other_disability</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1083994</td>\n",
              "      <td>He got his money... now he lies in wait till a...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-03-06 15:21:53.675241+00</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>317120</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>650904</td>\n",
              "      <td>Mad dog will surely put the liberals in mental...</td>\n",
              "      <td>train</td>\n",
              "      <td>2016-12-02 16:44:21.329535+00</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>154086</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5902188</td>\n",
              "      <td>And Trump continues his lifelong cowardice by ...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-09-05 19:05:32.341360+00</td>\n",
              "      <td>55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>374342</td>\n",
              "      <td>approved</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7084460</td>\n",
              "      <td>\"while arresting a man for resisting arrest\".\\...</td>\n",
              "      <td>test</td>\n",
              "      <td>2016-11-01 16:53:33.561631+00</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>149218</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5410943</td>\n",
              "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-06-14 05:08:21.997315+00</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>344096</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999511</th>\n",
              "      <td>1018736</td>\n",
              "      <td>Another man shamming article. If white men did...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-02-20 07:20:49.964620+00</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>169202</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999512</th>\n",
              "      <td>340016</td>\n",
              "      <td>\"no matter what is put in front of you regardi...</td>\n",
              "      <td>train</td>\n",
              "      <td>2016-06-06 06:43:04.780968+00</td>\n",
              "      <td>21</td>\n",
              "      <td>339965.0</td>\n",
              "      <td>137961</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999513</th>\n",
              "      <td>919629</td>\n",
              "      <td>The Democrat party aided and abetted by it's M...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-01-30 02:44:29.168863+00</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>164845</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999514</th>\n",
              "      <td>5165492</td>\n",
              "      <td>I just don't find her a very good representati...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-04-22 18:42:02.442987+00</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>328877</td>\n",
              "      <td>approved</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003717</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>269</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999515</th>\n",
              "      <td>4984105</td>\n",
              "      <td>You know the Trump fanatics are trolling the G...</td>\n",
              "      <td>train</td>\n",
              "      <td>2017-03-10 00:55:35.369198+00</td>\n",
              "      <td>54</td>\n",
              "      <td>807615.0</td>\n",
              "      <td>156960</td>\n",
              "      <td>approved</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00064</td>\n",
              "      <td>1562</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1999516 rows × 46 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d60f635-8f58-4ce4-9720-f7c1c09e1374')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d60f635-8f58-4ce4-9720-f7c1c09e1374 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d60f635-8f58-4ce4-9720-f7c1c09e1374');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzaGp_3oRrJd",
        "outputId": "dff55a40-e8b6-4c61-cb08-8d38f2c17984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1999516"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "6GeOzqxiS8ji",
        "outputId": "868c5af3-4069-4adc-bcfd-dc38702b12b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id  publication_id     parent_id    article_id         funny  \\\n",
              "count  1.999516e+06    1.999516e+06  1.134709e+06  1.999516e+06  1.999516e+06   \n",
              "mean   4.065400e+06    4.988997e+01  3.715138e+06  2.810257e+05  2.776687e-01   \n",
              "std    2.527563e+06    2.771895e+01  2.451507e+06  1.040778e+05  1.054819e+00   \n",
              "min    5.984800e+04    2.000000e+00  6.100600e+04  2.006000e+03  0.000000e+00   \n",
              "25%    8.565798e+05    2.100000e+01  7.930110e+05  1.600038e+05  0.000000e+00   \n",
              "50%    5.340220e+06    5.400000e+01  5.217531e+06  3.319250e+05  0.000000e+00   \n",
              "75%    5.955782e+06    5.400000e+01  5.774684e+06  3.662270e+05  0.000000e+00   \n",
              "max    7.194640e+06    1.150000e+02  6.333965e+06  3.995440e+05  1.020000e+02   \n",
              "\n",
              "                wow           sad         likes      disagree      toxicity  \\\n",
              "count  1.999516e+06  1.999516e+06  1.999516e+06  1.999516e+06  1.999516e+06   \n",
              "mean   4.437174e-02  1.089289e-01  2.441188e+00  5.808151e-01  1.029241e-01   \n",
              "std    2.458644e-01  4.555570e-01  4.712994e+00  1.854332e+00  1.970386e-01   \n",
              "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "50%    0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
              "75%    0.000000e+00  0.000000e+00  3.000000e+00  0.000000e+00  1.666667e-01   \n",
              "max    2.100000e+01  3.100000e+01  3.000000e+02  1.870000e+02  1.000000e+00   \n",
              "\n",
              "       ...          white          asian         latino  \\\n",
              "count  ...  448000.000000  448000.000000  448000.000000   \n",
              "mean   ...       0.056534       0.011886       0.006151   \n",
              "std    ...       0.215175       0.086906       0.058828   \n",
              "min    ...       0.000000       0.000000       0.000000   \n",
              "25%    ...       0.000000       0.000000       0.000000   \n",
              "50%    ...       0.000000       0.000000       0.000000   \n",
              "75%    ...       0.000000       0.000000       0.000000   \n",
              "max    ...       1.000000       1.000000       1.000000   \n",
              "\n",
              "       other_race_or_ethnicity  physical_disability  \\\n",
              "count            448000.000000        448000.000000   \n",
              "mean                  0.008158             0.001351   \n",
              "std                   0.042429             0.017461   \n",
              "min                   0.000000             0.000000   \n",
              "25%                   0.000000             0.000000   \n",
              "50%                   0.000000             0.000000   \n",
              "75%                   0.000000             0.000000   \n",
              "max                   1.000000             1.000000   \n",
              "\n",
              "       intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
              "count                        448000.000000                  448000.000000   \n",
              "mean                              0.001117                       0.012068   \n",
              "std                               0.016391                       0.089072   \n",
              "min                               0.000000                       0.000000   \n",
              "25%                               0.000000                       0.000000   \n",
              "50%                               0.000000                       0.000000   \n",
              "75%                               0.000000                       0.000000   \n",
              "max                               1.000000                       1.000000   \n",
              "\n",
              "       other_disability  identity_annotator_count  toxicity_annotator_count  \n",
              "count     448000.000000              1.999516e+06              1.999516e+06  \n",
              "mean           0.001219              1.431667e+00              8.775720e+00  \n",
              "std            0.014114              1.763593e+01              4.331605e+01  \n",
              "min            0.000000              0.000000e+00              3.000000e+00  \n",
              "25%            0.000000              0.000000e+00              4.000000e+00  \n",
              "50%            0.000000              0.000000e+00              4.000000e+00  \n",
              "75%            0.000000              0.000000e+00              6.000000e+00  \n",
              "max            0.600000              1.866000e+03              4.936000e+03  \n",
              "\n",
              "[8 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b6569a6-da10-48ad-83df-eb551c3725c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>publication_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>funny</th>\n",
              "      <th>wow</th>\n",
              "      <th>sad</th>\n",
              "      <th>likes</th>\n",
              "      <th>disagree</th>\n",
              "      <th>toxicity</th>\n",
              "      <th>...</th>\n",
              "      <th>white</th>\n",
              "      <th>asian</th>\n",
              "      <th>latino</th>\n",
              "      <th>other_race_or_ethnicity</th>\n",
              "      <th>physical_disability</th>\n",
              "      <th>intellectual_or_learning_disability</th>\n",
              "      <th>psychiatric_or_mental_illness</th>\n",
              "      <th>other_disability</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.134709e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>448000.000000</td>\n",
              "      <td>1.999516e+06</td>\n",
              "      <td>1.999516e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.065400e+06</td>\n",
              "      <td>4.988997e+01</td>\n",
              "      <td>3.715138e+06</td>\n",
              "      <td>2.810257e+05</td>\n",
              "      <td>2.776687e-01</td>\n",
              "      <td>4.437174e-02</td>\n",
              "      <td>1.089289e-01</td>\n",
              "      <td>2.441188e+00</td>\n",
              "      <td>5.808151e-01</td>\n",
              "      <td>1.029241e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056534</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>0.006151</td>\n",
              "      <td>0.008158</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>0.001117</td>\n",
              "      <td>0.012068</td>\n",
              "      <td>0.001219</td>\n",
              "      <td>1.431667e+00</td>\n",
              "      <td>8.775720e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.527563e+06</td>\n",
              "      <td>2.771895e+01</td>\n",
              "      <td>2.451507e+06</td>\n",
              "      <td>1.040778e+05</td>\n",
              "      <td>1.054819e+00</td>\n",
              "      <td>2.458644e-01</td>\n",
              "      <td>4.555570e-01</td>\n",
              "      <td>4.712994e+00</td>\n",
              "      <td>1.854332e+00</td>\n",
              "      <td>1.970386e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.215175</td>\n",
              "      <td>0.086906</td>\n",
              "      <td>0.058828</td>\n",
              "      <td>0.042429</td>\n",
              "      <td>0.017461</td>\n",
              "      <td>0.016391</td>\n",
              "      <td>0.089072</td>\n",
              "      <td>0.014114</td>\n",
              "      <td>1.763593e+01</td>\n",
              "      <td>4.331605e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.984800e+04</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>6.100600e+04</td>\n",
              "      <td>2.006000e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.565798e+05</td>\n",
              "      <td>2.100000e+01</td>\n",
              "      <td>7.930110e+05</td>\n",
              "      <td>1.600038e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.340220e+06</td>\n",
              "      <td>5.400000e+01</td>\n",
              "      <td>5.217531e+06</td>\n",
              "      <td>3.319250e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.955782e+06</td>\n",
              "      <td>5.400000e+01</td>\n",
              "      <td>5.774684e+06</td>\n",
              "      <td>3.662270e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.666667e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.194640e+06</td>\n",
              "      <td>1.150000e+02</td>\n",
              "      <td>6.333965e+06</td>\n",
              "      <td>3.995440e+05</td>\n",
              "      <td>1.020000e+02</td>\n",
              "      <td>2.100000e+01</td>\n",
              "      <td>3.100000e+01</td>\n",
              "      <td>3.000000e+02</td>\n",
              "      <td>1.870000e+02</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.866000e+03</td>\n",
              "      <td>4.936000e+03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b6569a6-da10-48ad-83df-eb551c3725c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b6569a6-da10-48ad-83df-eb551c3725c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b6569a6-da10-48ad-83df-eb551c3725c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UsCt18uTiEa",
        "outputId": "c63fec51-b43e-4536-ddb5-79b871a08c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['comment_text', 'funny', 'wow', 'sad', 'likes', 'disagree', 'toxicity',\n",
              "       'severe_toxicity', 'obscene', 'sexual_explicit', 'identity_attack',\n",
              "       'insult', 'threat', 'male', 'female', 'transgender', 'other_gender',\n",
              "       'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual',\n",
              "       'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu',\n",
              "       'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian',\n",
              "       'latino', 'other_race_or_ethnicity', 'physical_disability',\n",
              "       'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
              "       'other_disability', 'identity_annotator_count',\n",
              "       'toxicity_annotator_count'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data[\"toxicity\"].to_numpy().tolist()"
      ],
      "metadata": {
        "id": "U3XkOZqhUZvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[\"comment_text\"].to_numpy().tolist()"
      ],
      "metadata": {
        "id": "4g1WlJPaUeNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X) , type(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uymq9bw9UkaF",
        "outputId": "228f1d79-3558-40dc-91bc-b39e7b528355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del data[\"parent_id\"]\n",
        "del data[\"id\"]\n",
        "del data[\"split\"]\n",
        "del data[\"created_date\"]\n",
        "del data[\"publication_id\"]\n",
        "del data[\"article_id\"]\n",
        "del data[\"rating\"]"
      ],
      "metadata": {
        "id": "6ORzYApeTrDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing data\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdvbFtSrSrzM",
        "outputId": "732cf7f2-add9-48b3-c3fa-bb5e43dd425e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pre_process_data(main , flag = False):\n",
        "\n",
        "    if (flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            Original Data\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" , main[0])\n",
        "        print(\"2 :\" ,main[1])\n",
        "        print(\"3 :\" ,main[2])\n",
        "        print(\"4 :\" ,main[3])\n",
        "        print(\"5 :\" ,main[4])\n",
        "\n",
        "\n",
        "    # Step 1 - lowercasing\n",
        "\n",
        "    lower_cased_data = []\n",
        "    for sent in main:\n",
        "        # if(type(sent) == float):\n",
        "        #     print(sent)\n",
        "        #     break\n",
        "        lower_cased_data.append(sent.lower())\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After Lower Casing\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,lower_cased_data[0])\n",
        "        print(\"2 :\" ,lower_cased_data[1])\n",
        "        print(\"3 :\" ,lower_cased_data[2])\n",
        "        print(\"4 :\" ,lower_cased_data[3])\n",
        "        print(\"5 :\" ,lower_cased_data[4])\n",
        "\n",
        "    # Step 2 - Tokenization\n",
        "\n",
        "    token = WhitespaceTokenizer()\n",
        "\n",
        "    tokenized_data = []\n",
        "    for sent in lower_cased_data:\n",
        "        tokenized_data.append(token.tokenize(sent))\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After Toeknization\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,tokenized_data[0])\n",
        "        print(\"2 :\" ,tokenized_data[1])\n",
        "        print(\"3 :\" ,tokenized_data[2])\n",
        "        print(\"4 :\" ,tokenized_data[3])\n",
        "        print(\"5 :\" ,tokenized_data[4])\n",
        "\n",
        "    \n",
        "    # Step 3 - removing stop words\n",
        "\n",
        "    stopWords = set(stopwords.words('english'))\n",
        "    no_stop_data = []\n",
        "\n",
        "    for li in tokenized_data:\n",
        "        temp = []\n",
        "        for word in li:\n",
        "            if (word not in stopWords):\n",
        "                temp.append(word)\n",
        "        no_stop_data.append(temp)\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After Stop Words removal\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,no_stop_data[0])\n",
        "        print(\"2 :\" ,no_stop_data[1])\n",
        "        print(\"3 :\" ,no_stop_data[2])\n",
        "        print(\"4 :\" ,no_stop_data[3])\n",
        "        print(\"5 :\" ,no_stop_data[4])\n",
        "\n",
        "    # Step 4 - removing punctuations\n",
        "\n",
        "    puncts = string.punctuation\n",
        "    no_punc_data = []\n",
        "\n",
        "    for li in no_stop_data:\n",
        "        temp = []\n",
        "        for word in li:\n",
        "            temp_word = \"\"\n",
        "            for alp in word:\n",
        "                if (alp not in puncts):\n",
        "                    temp_word += alp\n",
        "            temp.append(temp_word)\n",
        "        no_punc_data.append(temp)\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After Punctuations removal\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,no_punc_data[0])\n",
        "        print(\"2 :\" ,no_punc_data[1])\n",
        "        print(\"3 :\" ,no_punc_data[2])\n",
        "        print(\"4 :\" ,no_punc_data[3])\n",
        "        print(\"5 :\" ,no_punc_data[4])\n",
        "\n",
        "    # Step 5 - Removing white spaces\n",
        "\n",
        "    final_data = []\n",
        "\n",
        "    for li in no_punc_data:\n",
        "        temp = []\n",
        "        for word in li:\n",
        "            if (word != ''):\n",
        "                temp.append(word)\n",
        "        final_data.append(temp)\n",
        "\n",
        "    if(flag):\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print (\"            After White Space removal\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\"1 :\" ,final_data[0])\n",
        "        print(\"2 :\" ,final_data[1])\n",
        "        print(\"3 :\" ,final_data[2])\n",
        "        print(\"4 :\" ,final_data[3])\n",
        "        print(\"5 :\" ,final_data[4])\n",
        "\n",
        "    return final_data"
      ],
      "metadata": {
        "id": "CfWEnpQiRty8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(axis = 0 , inplace = True)"
      ],
      "metadata": {
        "id": "EWOufDJcWxvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JraRw_lAW39x",
        "outputId": "8b63dd32-8227-44d9-ba80-a3ef585b4734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "448000"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CaQ0UvIXGmg",
        "outputId": "139facb5-62e2-44ea-9ae8-9c6566841aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pre_processed = pre_process_data(X)"
      ],
      "metadata": {
        "id": "AChJEqk2VCGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_pre_processed"
      ],
      "metadata": {
        "id": "5vwn3t-qVhiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will need to join the tokenized inputs first\n",
        "X_final = []\n",
        "for i in range(len(X)):\n",
        "    inp = X[i]\n",
        "    X_final.append(' '.join(inp))"
      ],
      "metadata": {
        "id": "hzkz9AGLcWVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_final"
      ],
      "metadata": {
        "id": "z7nLnxdTcr7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "bkBdOhbkXmZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train , Y_test = train_test_split(X,Y)"
      ],
      "metadata": {
        "id": "owuWUEUEYHfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train)\n",
        "X_train = vectorizer.transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "fKC2Ve8vYOv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cniov2Nub_W5",
        "outputId": "9ae82aaf-158b-4822-bd9a-5620b4ba6b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "# Convert your textual data to a list of lists of words\n",
        "text_data = [sentence.split() for sentence in X]\n",
        "\n",
        "# Train a Word2Vec model on your text data\n",
        "model = Word2Vec(sentences=text_data, size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Convert your text data into vectors using the Word2Vec model\n",
        "vectors = []\n",
        "for sentence in text_data:\n",
        "    sentence_vector = np.zeros(100)\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            word_vector = model.wv[word]\n",
        "            sentence_vector += word_vector\n",
        "        except KeyError:\n",
        "            pass\n",
        "    vectors.append(sentence_vector)\n"
      ],
      "metadata": {
        "id": "wINjCMnVhHdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Ylw42shLgK",
        "outputId": "47647d42-0c3f-4e4e-c2a0-60941151eb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "448000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoLXTnePjz3y",
        "outputId": "2e6bedd1-faee-489e-ff18-2d24a50ac775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = pd.DataFrame(vectors)\n",
        "encodings.to_csv(\"encoding.csv\")"
      ],
      "metadata": {
        "id": "7cG6uRky4Vs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"encoding.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1KIpefPK4euR",
        "outputId": "87f7a292-21b2-4b34-c95c-182ab54bc8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4035332f-3554-4a0f-a94b-f69a6ec50ce9\", \"encoding.csv\", 852346738)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"encoding.csv\")"
      ],
      "metadata": {
        "id": "evLiSAtR6roS",
        "outputId": "750345f7-fdaa-482c-d21c-ad44632eb80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_281f17c4-96a0-4426-82ed-dafe325637cb\", \"encoding.csv\", 852346738)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train , Y_test = train_test_split(vectors,Y)"
      ],
      "metadata": {
        "id": "O_enI8BTkw6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train an SVM model on the training data\n",
        "clf = SVC(kernel='linear', C=1, random_state=42)\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the SVM model\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "YB6naFvjlh_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "ucz46fpX433q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "# Predict the labels for the test data\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the SVM model\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mQrpkb75FR_",
        "outputId": "6455b7d9-6638-4ba6-fc4a-9b34e4528d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9188839285714285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "zObpDZHa33_0",
        "outputId": "641b892c-4992-42ec-d319-4fbe41f12912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-931765772341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_temp = []\n",
        "for val in Y_train:\n",
        "    if val>0.5:\n",
        "        Y_train_temp.append(1)\n",
        "    else:\n",
        "        Y_train_temp.append(0)\n",
        "Y_train = Y_train_temp"
      ],
      "metadata": {
        "id": "9kAZZ8smmkNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test_temp = []\n",
        "for val in Y_test:\n",
        "    if val>0.5:\n",
        "        Y_test_temp.append(1)\n",
        "    else:\n",
        "        Y_test_temp.append(0)\n",
        "Y_test = Y_test_temp"
      ],
      "metadata": {
        "id": "11ZbJtBwmpxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pvZe6dfnQMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starring out toxic words"
      ],
      "metadata": {
        "id": "5ZKp2twD1fzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_words = []"
      ],
      "metadata": {
        "id": "YnfkaDvb1jCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detoxify(sent):\n",
        "\n",
        "    # First we will check whether the sent is toxic or not using our SVM model\n",
        "\n",
        "    # if the sent is not toxic then just return the original sentence\n",
        "\n",
        "    # else\n",
        "\n",
        "    detoxified_sentence = \"\"\n",
        "    for word in sent:\n",
        "        if(word in toxic_words):\n",
        "            # We found a toxic word\n",
        "            detoxified_sentence += '*'*len(word)\n",
        "        else:\n",
        "            detoxified_sentence += word\n",
        "    return detoxified_sentence"
      ],
      "metadata": {
        "id": "bxK4-nZ11lSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}